---
title: "Chapter III: Changes in conceptual units"
output:
  html_notebook:
    toc: yes
    toc_depth: 4
    toc_float: yes
always_allow_html: yes
---

```{r global_options, include = F}
knitr::opts_chunk$set(fig.width = 3, fig.asp = 0.67,
                      include = F, echo = F)
```

```{r}
# # for knitting to .docx
# output:
#   word_document:
#     reference_docx: "./word-styles-reference.docx"
# always_allow_html: yes
   
# # for knitting to .nb.html 
# output:
#   html_notebook:
#     toc: yes
#     toc_depth: 4
#     toc_float: yes
```

```{r}
# supporting functions
source("./scripts/max_factors_efa.R")
source("./scripts/reten_fun.R")
source("./scripts/plot_fun.R")
source("./scripts/efa_fun.R")
source("./scripts/ms_fun.R")

# data scripts
source("./scripts/data_s1.R")
source("./scripts/data_s2_ad.R")
source("./scripts/data_s2_79.R")
source("./scripts/data_s3_ad.R")
source("./scripts/data_s3_79.R")
source("./scripts/data_s3_46.R")
source("./scripts/data_s4_ad.R")
source("./scripts/data_s4_46.R")
```


# Chapter overview

In this chapter, I focus on the first of my three key questions about the development of representations of mental life introduced in Chapter I: _What are the components, or "conceptual units," that anchor representations of mental life at different points in development?_ As described in Chapter II, to address this question I draw on data from all of the current studies (Studies 1-4); for details about the methods of these studies, see Chapter II. The goal of this chapter is to provide "snapshots" of the sets of conceptual units available to participants in early childhood, middle childhood, and adulthood. 

(Note that this was the primary planned analysis for all of the studies included in this dissertation; see, e.g., Weisman et al., 2017.)


# General analysis plan: Identifying conceptual units

In analyzing these datasets with an eye toward identifying "conceptual units," the basic insight is that tracking the covariance of mental capacity attributions provides a way of discovering suites of mental capacities that "hang together" in reasoning about mental life, and that these suites of mental capacities might correspond to the units of some larger conceptual representation of this general domain. To borrow an example from Chapter II: If participants who endorse Capacity X also tend to endorse Capacities Y and Z, this provides some evidence that Capacities X, Y, and Z consitute a suite of mental capacities that are closely associated with the same underlying "conceptual unit." 

In other words, my goal in the current chapter is to uncover a set of latent constructs—"conceptual units"—that could have given rise to the correlations among mental capacity attributions as observed in a given group of participants. A canonical way to identify latent constructs via observed correlations is exploratory factor analysis (EFA), a form of dimensionality reduction that posits that the observed variables in a given dataset are related, to varying degrees, to a smaller set of unobserved "factors"; and that individual observations of each of these variables reflect a combination of the state of these latent factors, a particular variable's relationship to each of these latent factors, and noise. Following this logic, I posit that, for any of the current datasets, the many mental capacities included in that dataset are related, to varying degrees, to a smaller set of latent "conceptual units"; and that a participant's attributions of each of these mental capacities to a particular target character reflect a combination of that participant's beliefs about the extent to which these conceptual units apply to that target character, a particular mental capacity's relationships to each of these conceptual units, and noise. In other words, one way to identify conceptual units for a particular sample of interest (e.g., US adults; children of different age groups) is to conduct an EFA over participants' mental capacity attributions and treat the resulting "factors" as candidate conceptual units.

In the remainder of this chapter, I report EFAs for each age group included in each of the current studies (Studies 1-4). Conducting an EFA requires making a variety of analysis choices, including how to handle missing data, what kind of correlations to use, the choice of factoring algorithm, how to determine the number of factors to retain, the choice of rotation method (if any), and the method for calculating factor scores. In the analysis code for this chapter I have included easy short-cuts for the interest reader to explore different options for each of these parameters. Here, I have set all of these parameters to be constant across EFAs of different samples so as to maximize comparability across studies:

```{r}
# what correlation to use
chosen_cor <- "cor" # REPORTED
# chosen_cor <- "poly" # alternative option

# what rotation to use
chosen_rot <- "varimax" # REPORTED
# chosen_rot <- "oblimin" # alternative option

# what factoring method to use
chosen_fm <- "minres" # REPORTED (minimum residuals)
# chosen_fm <- "ols" # ordinary least squares using empirical first derivative
# chosen_fm <- "wls" # weighted least squares
# chosen_fm <- "gls" # generalized weighted least squares
# chosen_fm <- "pa" # principal factors
# chosen_fm <- "ml" # maximum likelihood
# chosen_fm <- "minchi" # minimize ss-weighted chisq
# chosen_fm <- "minrank" # minimum rank
# chosen_fm <- "old.min" # minres < April 2017
# chosen_fm <- "alpha" # alpha fa (Kaiser & Coffey, 1965)

# what scoring method to use
chosen_scores <- "tenBerge" # REPORTED
# chosen_scores <- "regression" # alternative option
```

```{r}
# overview of missing data
n_missing <- NULL
for(i in list(d1a_ad_wide, d1b_ad_wide, d1c_ad_wide, d1d_ad_wide,
              d2_ad_wide, d2_79_wide, d3_ad_wide, d3_79_wide, d3_46_wide,
              d4_ad_wide, d4_46_wide)){
  n_missing <- c(n_missing, missing_percent_fun(i))
}
```

- _Missing data_: For all EFAs, I impute missing trial-level data (e.g., skipped trials among child particpiants) using the median response for that mental capacity among other participants who evaluated the same target character. For example, if an 8-year-old participant in the "beetle" condition failed to provide a response to a question about a beetle's capacity for happiness, I set this response to be the median response to the happiness question among of all other children from the 7- to 9-year-old age group for that study who evaluated the beetle (ignoring children who evaluated some other target character). Across all studies, fewer than `r round(max(n_missing), 2) + 0.01`% of trials in any age group were missing data. In my judgment, the advantages of retaining the most participants per sample (particularly for EFA, which is highly sensitive to sample size) justifies imputing values for this small number of missing datapoints. 
- _Correlations_: I conduct analyses over Pearson correlations among mental capacity attributions, using pairwise complete observations. In principle, polychoric correlations are better suited to handle responses on the three-point scales employed in Studies 2-4; however, in my experience with these data, conducting EFAs with polychoric correlations instead of Pearson correlations tends to generate errors further down the analysis pipeline (e.g., generating correlation matrices that are not positive definite) and appears to be somewhat vulnerable to over-fitting (e.g., suggesting retaining many factors that each accounted for only a very small amount of the shared variance).
- _Factoring algorithm_: I use ordinary least squares to find the minimum residual solution, which is robust to a variety of ways that matrices can be "badly behaved" (see Revelle, 2018). While this dissertation does not include a systematic exploration of all of the possible options, in my casual explorations of the various algorithms available I have yet to observe any substantial differences to the number of factors retained or to the resulting solutions that would change the interpretations offered here.
- _Factor retention protocol_: I examine the results of three factor retention protocols: (1) Parallel Analysis, which compares the observed correlation structure to the correlation structure arising from random datasets of the same size; (2) Minimizing the Bayesian Information Criterion (BIC), which is one method of optimizing both goodness of fit and parsimony; and (3) A set of factor retention criteria that I have used previous work with adults (Weisman et al., 2017), in which I begin with the maximal number of factors according to an analysis of degrees of freedom and retain factors that meet all three of the following criteria: (a) have eigenvalues greater than 1.00, (b) individually account for greater than 5% of the shared variance before rotation, and (c) are the "dominant" factor (the factor with the strongest absolute factor loading) for at least 1 mental capacity after rotation. For each study, my interpretation of how best to characterize the dataset (i.e., how many factors I observed) is determined by the degree of consensus among these three protocols and the interpretability of the retained factors under each protocol. (See Table 3.1 for the results of all factor retention protocols for all studies and samples.)
- _Rotation_: To maximine interpretability factors, I present varimax-rotated solutions, which constrain all factors to be orthogonal. (For solutions using oblique ["oblimin"] rotations, which allow for correlated factors, [XX SEE APPENDIX?].)
- _Factor scores_: I use the method developed by ten Berge, Krijnen, Wansbeek, & Shapiro (1999) to calculate factor scores, as suggested by Revelle (2018). (I include this parameter here for completeness; this chapter does not include any analyses of factor scores.)

To conduct these EFAs, I use the "psych" package for R (Revelle, 2018).


# Study 1: An adult endpoint

An in-depth analysis and discussion of the conceptual units available to US adults in Studies 1a-1d is provided in our previously published work on these studies (Weisman et al., 2017). Here I present these analyses anew, with slight tweaks to the analysis pipeline to maximize comparability to Studies 2-4. These results serve as the backdrop for the extended anaysis of conceptual development in this domain that is the focus of this dissertation.

__NOTE TO SELF: CHECK SAMPLE SIZES AGAINST PNAS PAPER. EXCLUSION CRITERIA??__

## Special notes on data processing and analysis

As noted in Chapter II, in the original analysis of these datasets responses were recoded to run from -3 to +3 before analyses (Weisman et al., 2017); in this dissertation, I maintain the 0-6 coding for comparability to Studies 2-4.

In Study 1c, participants assessed two target characaters side by side (in contrast to Studies 1a, 1b, and 1d, in which each participant assessed just one target character). In the current analyses, I treat each participant's assessments of each target character as a separate set of observations (as if they came from different participants), in effect doubling the sample size for these studies (but ignoring the within-subject design). ([XX SEE APPENDIX?] for separate EFAs of the participants' responses to the first target character that they were assigned to rate vs. the second character.)

## Results

```{r}
reten_report <- list("Study 1a" = d1a_ad_wide_i, 
                     "Study 1b" = d1b_ad_wide_i,
                     "Study 1c" = d1c_ad_wide_i, 
                     "Study 1d" = d1d_ad_wide_i,
                     "Study 2: Adults" = d2_ad_wide_i,
                     "Study 2: Children (7-9y)" = d2_79_wide_i,
                     "Study 3: Adults" = d3_ad_wide_i,
                     "Study 3: Older children (7-9y)" = d3_79_wide_i,
                     "Study 3: Younger children (4-6y)" = d3_46_wide_i,
                     "Study 4: Adults" = d4_ad_wide_i,
                     "Study 4: Children (4-5y)" = d4_46_wide_i) %>% 
  reten_report_fun()
```

```{r}
reten_report_byprotocol <- reten_report %>% 
  gather(protocol, nfact) %>% 
  group_by(protocol) %>% 
  summarise(min = min(nfact), 
            max = max(nfact), 
            mean = mean(nfact), 
            median = median(nfact)) %>%
  ungroup()

reten_report_byprotocol
```

```{r}
reten_report_bystudy <- reten_report %>% 
  rownames_to_column("study") %>%
  gather(protocol, nfact, -study) %>% 
  group_by(study) %>% 
  summarise(min = min(nfact), 
            max = max(nfact), 
            mean = mean(nfact), 
            median = median(nfact)) %>%
  ungroup()

reten_report_bystudy
```

### Study 1a

In Study 1a, `r nrow(d1a_ad_wide)` US adults each assessed a single target character on 40 mental capacities. This study employed the "edge case" variant of the general approach, with participants randomly assigned to assess either a beetle or a robot. (See Chapter II and Weisman et al., 2017, for detailed methods.)

```{r}
table3.1 <- reten_report %>%
  rownames_to_column("study") %>%
  full_join(reten_report_bystudy) %>%
  # column_to_rownames("study") %>%
  mutate(mean = round(mean, 2),
         study = gsub("Study ", "", study),
         study = gsub(".\\: ", "", study)) %>%
  rename(` ` = study, 
         `parallel analysis` = par,
         `minimizing BIC` = bic,
         `Weisman et al. (2017)` = wdm,
         `min.` = min,
         `max.` = max) %>%
  kable(format = "html", #align = c("l", rep("r", 3)),
        caption = "Table 3.1: Number of factors suggested by three factor retention protocols: Parallel Analysis, Minimizing BIC, and the preset factor retention criteria specified in Weisman et al. (2017). Results are grouped by study and age group.") %>%  
  kable_styling() %>%
  group_rows("Study 1: An adult endpoint", 1, 4) %>%
  group_rows("Study 2: Conceptual change between middle childhood (7-9y) and adulthood", 5, 6) %>%
  group_rows("Study 3: Conceptual change over early and middle childhood (4-9y)", 7, 9) %>%
  group_rows("Study 4: A focus on early childhood (4-5y)", 10, 11) %>%
  add_header_above(c(" " = 1, "Protocol alternatives" = 3, 
                     "Summary of suggestions" = 4)) %>%
  column_spec(4, border_right = T)
```

```{r table3.1, include = T}
table3.1
```

### Study 1b

Study 1b was a direct replication of Study 1a: `r nrow(d1b_ad_wide)` US adults each assessed a single target character (either a beetle or a robot) on 40 mental capacities. (See Chapter II and Weisman et al., 2017, for detailed methods.)

### Study 1c

In Study 1c, `r nrow(d1c_ad_wide)/2` US adults each assessed two target characters on 40 mental capacities. Like Studies 1a and 1b, this study employed the "edge case" variant of the general approach; but in this study, all participants assessed both of these target characters side by side (with left-right position counterbalaned across participants). (See Chapter II and Weisman et al., 2017, for detailed methods.)

### Study 1d

In Study 1d, `r nrow(d1d_ad_wide)` US adults each assessed a single target character on 40 mental capacities. Unlike Studies 1a-1c, this study employed the "many characters" variant of the general approach, in which participants were randomly assigned to assess one of the following 21 target characters: an adult, a child, an infant, a person in a persistent vegetative state, a fetus, a chimpanzee, an elephant, a dolphin, a bear, a dog, a goat, a mouse, a frog, a blue jay, a fish, a beetle, a microbe, a robot, a computer, a car, or a stapler. (See Chapter II and Weisman et al., 2017, for detailed methods.)

## Discussion


# Study 2: Conceptual change between middle childhood (7-9y) and adulthood

In Study 2, `r nrow(d2_ad_wide)` US adults and `r nrow(d2_79_wide)` US children between the ages of `r summary(d2_79$age)["Min."] %>% round(2)`-`r summary(d2_79$age)["Max."] %>% round(2)` years (median: `r summary(d2_79$age)["Median"] %>% round(2)`y) each assessed a single target character on 40 mental capacities. To make the study appropriate for children in this age range, the wording of some the 40 mental capacities employed in Study 1 was modified to use more age-appropriate vocabulary, and participants responded on a 3-point scale ("no," coded as 0; "kinda," coded as 0.5, "yes," coded as 1). This study employed the "edge case" variant of the general approach, with participants randomly assigned to assess either a beetle or a robot. (See Chapter II for detailed methods.)

## Special notes on data processing and analysis

## Results

### Adults

### Children (7-9y)

## Discussion


# Study 3: Conceptual change over early and middle childhood (4-9y)

In Study 3, `r nrow(d3_ad_wide)` US adults, `r nrow(d3_79_wide)` "older" children (`r summary(d3_79$age)["Min."] %>% round(2)`-`r summary(d3_79$age)["Max."] %>% round(2)` years; median: `r summary(d3_79$age)["Median"] %>% round(2)`y), and `r nrow(d3_46_wide)` "younger" children (`r summary(d3_46$age)["Min."] %>% round(2)`-`r summary(d3_46$age)["Max."] %>% round(2)` years; median: `r summary(d3_46$age)["Median"] %>% round(2)`y) each assessed a single target character on 20 mental capacities. To make the study appropriate for children in this age range, participants assessed a subset of the 40 mental capacities employed in Study 2, chosen to represent the three "conceptual units" revealed by Studies 1-2 (BODY, HEART, and MIND) and to cover a similar range of mental capacities as Studies 1-2. As in Study 2, participants responded on a 3-point scale ("no," coded as 0; "kinda," coded as 0.5, "yes," coded as 1). This study employed the "diverse characters" variant of the general approach, with participants randomly or pseudo-randomly assigned to assess either one of the following 9 characters: an elephant, a goat, a mouse, a bird, a beetle, a teddy bear, a doll, a robot, or a computer. (See Chapter II for detailed methods.)

## Special notes on data processing and analysis

## Results

### Adults

### Older children (7-9y)

### Younger children (4-6y)

## Discussion


# Study 4: A focus on early childhood (4-5y)

In Study 4, `r nrow(d4_ad_wide)/2` US adults and `r nrow(d4_46_wide)/2` US children between the ages of `r summary(d4_46$age)["Min."] %>% round(2)`-`r summary(d4_46$age)["Max."] %>% round(2)` years (median: `r summary(d4_46$age)["Median"] %>% round(2)`y) each assessed two target characters on 18 mental capacities. To make the study appropriate for children in this age range, this study employed a new set of 18 mental capacities (some but not all of which were used in Studies 1-3). In addition, participants were presented with a more child-friendly visual representation of the 3-point response scale ("no," coded as 0; "kinda," coded as 0.5, "yes," coded as 1). This study employed the "edge case" variant of the general approach, with participants assessing both a beetle or a robot in sequence (with order counterbalanced across participants). (See Chapter II for detailed methods.)

As briefly described in Chapter II, the 18 mental capacities employed in Study 4 were selected from a larger pilot study in which 3- to 5-year-old children were asked to complete stories that began with each of these mental capacities as a premise (e.g., "Let's imagine a person who _loves someone_. What happens next?"; "Now let's pretend that someone _remembers something_. What happens next?") and were judged on the appropriateness of their story completion. 

Among the items that emerged from this pilot study as reasonable candidates for inclusion in Study 4, I selected items to represented the three "conceptual units" revealed by Studies 1-3 (BODY, HEART, and MIND). The goal here was to create a conservative test of developmental differences between younger and older children in the "conceptual units" observed in Study 3, by constructing materials that should maximize the chances of observing the same (or similar) conceptual units among young children as were observed among older children and adults in Studies 1-3. If 4- to 5-year-old children in fact have access to conceptual units similar to BODY, HEART, and MIND, the mental capacities (and generally child-friend protocol) of Study 4 should provide the best chances of surfaces this conceptual structure. Conversely, if Study 4 reveals differences in conceptual structure despite these modifications, and despite "stacking the odds" against developmental differences in the selction of mental capacities, this provides stronger evidence for conceptual change in the number and/or kind of conceptual units available to children at different points in development.

## Special notes on data processing and analysis

In Study 4, participants assessed two target characaters side by side (in contrast to Studies 1a, 1b, 1d, 2, and 3, in which each participant assessed just one target character). In the current analyses, I treat each participant's assessments of each target character as a separate set of observations (as if they came from different participants), in effect doubling the sample size for these studies (but ignoring the within-subject design). ([XX SEE APPENDIX?] for separate EFAs of the participants' responses to the first target character that they were assigned to rate vs. the second character.)

## Results

### Adults

### Children (4-5y)

## Discussion


# General discussion of conceptual units


# Chapter conclusion








# SCRAPS





Scraps:
- [FOR TRANSITION FROM STUDY 2 TO STUDY 3]: As demonstrated in Study 1, among adults the "edge case" and "diverse characters" variants of the general approach have yielded very similar pictures of conceptual representations (see also XX CITE Weisman et al., 2017). If this three-part conceptual structure is stable and robust by the age of 7-9 years, it should manifest among 7- to 9-year-old children under the same range of conditions that it does among adults. Thus, in Study 3...
- [FOR TRANSITION FROM STUDY 3 to STUDY 4]: For the final set of questions, I aimed to select six clear examples of physiological sensations (_BODY_), social-emotional abilities (_HEART_), and perceptual-cognitive capacities (_MIND_), according to Studies 1-2 and Weisman et al.'s (2017) original studies with US adults. We reasoned that if these carefully selected examples of _BODY_, _HEART_, and _MIND_ still elicited differences in correlational structures between 4- to 5-year-old children and adults, this would be particularly strong evidence of age-related changes in conceptual structure. The final set of _BODY_ items included _feel hungry_, _get thirsty_, _feel sick_, _feel tired_, _get scared_, and _smell things_. _HEART_ items included _love someone_, _hate someone_, _feel happy_, _get sad_, _feel sorry_, and _get lonely_. _MIND_ items included _see_, _hear_, _think_, _remember things_, _know stuff_, and _figure things out_. We ensured that each category included a variety of phrasings (e.g., "_feel_ hungry" vs. "_get_ thirsty"; "remember _things_" vs. "know _stuff_") and valences when appropriate (e.g., happiness vs. sadness); when possible, we aimed to have these aspects of phrasing vary orthogonally with categories, such that "get" and "feel" appeared roughly equally often among the _BODY_ and _HEART_ items, and "things" appeared equally often among the _BODY_ and _MIND_ items. 
