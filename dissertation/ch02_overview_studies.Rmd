---
title: "Chapter II: Overview of studies"
output:
  html_notebook:
    toc: yes
    toc_depth: 4
    toc_float: yes
always_allow_html: yes
---

```{r global_options, include = F}
knitr::opts_chunk$set(fig.width = 3, fig.asp = 0.67,
                      include = F, echo = F)
```

```{r}
# # for knitting to .docx
# output:
#   word_document:
#     reference_docx: "./word-styles-reference.docx"
# always_allow_html: yes
   
# # for knitting to .nb.html 
# output:
#   html_notebook:
#     toc: yes
#     toc_depth: 4
#     toc_float: yes
```

Here I provide an overview of the methods and analyses for the four sets of studies that form the backbone of this dissertation. These studies all used very similar experimental paradigms to address our three key questions about conceptual representations of mental life at various points in development: (1) _What are the components, or "conceptual units," that anchor representaitons of mental life?_; (2) _How are these conceptual units organized in relation to each other?_; and (3) _How is this conceptual representation of mental life deployed in reasoning about specific entities in the world?_. In subsequent chapters (Chapters III-IV), each study will be described in detail. This chapter is intended to provide the reader with a general sense of the methods and analysis approaches common to all studies.

# General approach

There are many approaches that one could take to studying conceptual representations of mental life. For example, one could focus on representations of _human_ minds in particular, and ask participants to reason about how different mental states unfold over time in a causal chain (e.g., a person's visual perception causing them to form a belief, or to have an emotional reaction; XX CITE Wellman). Conversely, one could ask participants to reason about the mental lives of unfamiliar or unknown entities (e.g., XX CITE Weisman, Markman, & Dweck, 2015 CogSci). One could also ask participants explicitly about their understanding of mental capacities themselves, rather than inferring these conceptual representations from questions about the mental lives of any particular entity, human or otherwise (e.g., asking questions like, "Is planning a part of deciding?" or "Is remembering a kind of thinking?", XX CITE Rips & Conrad, 1989; "How similar are these words: happy and sad?", XX CITE Nook et al., 2017; see also XX CITE Fabricius, Schwanenflugel). All of these approaches have proved to be useful ways of examining how people represent the mind.

In the current studies, however, I instead chose to examine conceptual representations of mental life by documenting participants' mental capacity attributions to a wide variety of entities that might be perceived to vary in their mental lives (e.g., humans, non-human animals, technologies, and inert objects). In particular, these studies were designed to capture participants' beliefs about the _co-occurrence_ of a diverse range of mental capacities: When a participant indicates that an entity has one capacity (e.g., for pain, or happiness, or memory), what other capacities do they tend to attribute to that entity?

This general strategy has been employed by several research teams in studies of adults' understanding of the mind, yielding fascinating results that have been met with great interest in the burgeoning field of "mind perception" (XX CITE Gray et al., maybe Haslam? maybe Weisman et al.). In my view, this approach offers several advantages over the approaches described in the previous paragraph. At its core, this approach centers on asking participants straightforward, concrete questions, drawing on their intuitions about familiar entities in the world (e.g., "Can a robot feel happy?", "Can a beetle remember things?"). In particular, asking many such questions about a single target entity, provides a natural way to focus participants' attention on the similarities, differences, and relationships among a wide range of mental capacities (a point I emphasized in writing about my initial studies with adults, which will be discussed in Chapter III; see Weisman et al., 2017). Such questions may be easier, quicker, and more enjoyable for particpants - both adults and children - to answer than the more abstract, hypothetical, or metacognitive tasks described above. As such, it opens up the possibility of using the same experimental method to study conceptual representations across a wide age range, including even quite young children (4y).

[XX wrap up]

# Common methods

[XX introduce]

To this end, each participant was either randomly or pseudo-randomly assigned to assess 1-2 target characters (e.g., a beetle, a robot, a goat, etc.) on a wide range of sensory, perceptual, emotional, social, cognitive, and other mental capacities, ranging in number from 18-40 across studies and presented in either a random or a pseudo-random (counterbalanced) order. Participants were presented with a vivid, full-color photograph of their assigned target in a naturalistic context (e.g., a beetle on a leaf; a robot in an office; a goat in a grassy field), which they had access to throughout the study. 

On each trial, participants were asked a question of the form Do you think a [target] can [do X]? (e.g., "Do you think a beetle can feel happy?"; Studies 1-2) or Can [targets] [do X]? (Study 3) (e.g., "Can beetles feel happy?"). Participants responded on a three-point scale (no, coded as 0; kinda, coded as 0.5; or yes, coded as 1). Although a three-point scale is not optimal for factor analyses, pilot testing suggested that it was critical in allowing children to move fast enough through the study to answer all questions, and maintaining this within-subjects design was our top priority for the planned analyses.

See the Methods section for each study for details of the particular target characters and mental capacities included in each study, as well as the materials and physical setup.

## Exploring conceptual structure through exploratory factor analysis (EFA)

Our primary goal in conducting these studies was to uncover a set of latent constructs that might plausibly have given rise to the observed correlations among mental capacity attributions in each group of participants. As such, our primary planned analysis for all studies was an exploratory factor analysis (EFA). Following Weisman et al. (2017), we interpreted each of the constructs ("factors") as corresponding to a fundamental component of mental life, according to this group of participants; by extension, we consider the full set of factors for each sample to represent to the overall "conceptual structure" underlying mental capacity attributions for this group of participants.

For all EFAs, we used ordinary least squares to find the minimum residual solution, using the "psych" package for R (Revelle, 2018). Here we focus on results using Pearson correlations using pairwise complete observations. (See Online Supplementary Materials [OSM] for solutions using polychoric correlations, which are better suited to handle responses on a three-point scale but, to our eyes, tended to over-fit our data by suggesting that we should retain many factors that each accounted for only a small amount of the shared variance.)

In order to determine how many factors to retain, we examined the results of three factor retention protocols: (1) Parallel Analysis, which compares the observed correlation structure to the correlation structure arising from random datasets of the same size; (2) Minimizing the Bayesian Information Criterion (BIC), which is one method of optimizing both goodness of fit and parsimony; and (3) A set of factor retention criteria that have been used in Weisman et al.'s (2017) previous work, in which they began with the maximal number of factors according to an analysis of degrees of freedom, and retained factors that met all three of the following criteria: (a) had eigenvalues greater than 1.00, (b) individually accounted for greater than 5% of the shared variance before rotation, and (c) were the "dominant" factor (the factor with the strongest absolute factor loading) for at least 1 mental capacity after rotation. For each study, our interpretation of how best to characterize the dataset (i.e., how many factors we observe) was determined by the degree of consensus among these three protocols and the interpretability of the retained factors under each protocol. 

Here we focus our interpretations on varimax-rotated solutions, which constrain all factors to be orthogonal. (See OSM for solutions using oblique ["oblimin"] rotations, which allow for correlated factors.)

## Charting differences in the application of these concepts through regression analyses of factor scores

Having inferred a conceptual structure for a given group of participants via EFA, we then sought to examine attributions of mental capacities to the particular target characters included in each study within this conceptual structure: To what extent did participants attribute each of the fundamental components of mental life revealed by EFA to a given target character, and how did this attributions vary with age (either within an age group or between age groups)? 

To explore this question, for each study we projected children's data into adults' conceptual space and examined "factor scores"—summaries of each participant's attributions of each of factors revealed by EFA. We used the correlation-preserving "ten Berge" method (as implemented in the "psych" package; Revelle, 2018), imputing missing values using the mean (by target character, capacity, and age group). This yielded one factor score for each of (adults') factors, for each participant. We consider these to be summaries of that person's attributions of the corresponding latent construct.

We analyzed these factor scores via mixed effects Bayesian regression analyses using the "brms" package for R (Bürkner, 2017). In all of these analyses, we included the maximal random effect structures given the design for the relevant study. Further details varied by study, depending on the number of target characters included in that study, the number of factors revealed by EFA for the relevant group(s) of participants, and the goals of the analysis (e.g., comparing two age groups vs. examining continuous effects of age within one or more groups of participants).
