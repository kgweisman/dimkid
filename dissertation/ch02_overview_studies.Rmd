---
title: "Chapter II: Overview of methods"
output:
  word_document:
    reference_docx: "./word-styles-reference.docx"
always_allow_html: yes
---

```{r global_options, include = F}
knitr::opts_chunk$set(fig.width = 3, fig.asp = 0.67,
                      include = F, echo = F)
```

```{r}
# # for knitting to .docx
# output:
#   word_document:
#     reference_docx: "./word-styles-reference.docx"
# always_allow_html: yes
   
# # for knitting to .nb.html 
# output:
#   html_notebook:
#     toc: yes
#     toc_depth: 4
#     toc_float: yes
```

```{r}
# run ur-setup script (which runs other scripts)
source("./scripts/_SETUP.R")
```


# Chapter overview

In the following chapters, I address the three key questions about the development of representations of mental life introduced in the previous chapter: (1) _What are the components, or "conceptual units," that anchor representations of mental life at different points in development?_ (Chapter III); (2) _How are these conceptual units organized in relation to each other, and how does this organization change over development?_ (Chapter IV); and (3) _How do people of different ages deploy their conceptual representations of mental life to reason about specific entities in the world—namely, animate beings vs. inanimate objects?_ (Chapter V). 

The organization of Chapters III-V is somewhat unconventional. Rather than introducing a new study in each chapter, I analyze data from all four studies in Chapter III, and then return to re-analyze these same datasets in Chapter IV, and again in Chapter V; in other words, instead of proceeding study by study (including multiple analyses for each study), I proceed analysis by analysis, drawing on the full set of studies for each analysis. My goal in presenting these results in this unusual manner is to paint a holistic picture of developmental change in each of these  distinct aspects of conceptual representation, without requiring the reader to look back and forth between chapters to make comparisons across parallel analyses (or switch back and forth between different complex analyses within a single chapter).

With this roadmap in mind, in the current chapter I describe the methods for all of the studies included in this dissertation ("Methods"). This chapter is intended to give the reader a general sense of the studies included in this dissertation and to provide the reader with an easily accessible resource for finding details about any particular study as it becomes relevant in Chapters III-VI.


# General approach

In this dissertation, I examine conceptual representations of mental life by documenting participants' mental capacity attributions to a wide variety of familiar entities that might be perceived to vary in their mental lives, including humans, non-human animals, technologies, and inert objects. These studies were designed to capture participants' beliefs about the _co-occurrence_ of a diverse range of mental capacities: When someone indicates that some entity has one capacity (e.g., for pain, or happiness, or memory), what other capacities does that person tend to attribute to that entity? The goal of these studies was to facilitate participants' engagement with deep questions about the nature of mental life—in particular, the similarities, differences, and relationships among different mental capacities—through simple questions grounded in concrete, real-world examples. 

My general approach was inspired by Gray et al.'s (XX CITE GRAY et al. 2007) landmark study on what they called "the dimensions of mind perception" (discussed at length in Chapter I). In this study, each participant answered questions about many pairs of target characters (e.g., a robot vs. a fetus, a baby vs. an adult woman, an adult man vs. a chimpanzee, a dog vs. God), while focusing  on a single mental capacity (e.g., joy). In other work on adults' understanding of the mind, participants have compared the mental capacities of different classes of target characters to humans as a point of reference (e.g., animals vs. humans, robots vs. humans, supernatural beings vs. humans; XX CITE HASLAM et al. 2008).

In the current studies, I took a slightly different approach. Instead of asking participants to compare the relative mental capacities of many different characters or classes of characters, I asked participants to assess a wide variety of mental capacities for just one or two target characters (e.g., assessing a robot on many different sensory, perceptual, emotional, cognitive, and social abilities). As I have argued elsewhere (XX CITE WEISMAN et al. 2017; see also Chapter I), asking each participant to assess many mental capacities for just one or two target characters confers the major advantage of focusing participants' attention on the similarities, differences, and relationships among a wide range of mental capacities (rather than on the similarities, differences, and relationships among various target characters). Moreover, as I argued in Chapter I, because this approach centers on asking participants straightforward questions in relatively simple language, it opens up the possibility of using the same experimental method to study conceptual representations across a wide age range—the primary goal of this dissertation. 

These studies are based on the premise that _variability across participants_ in their mental capacities can shed light on the three aspects of conceptual representation that are the focus of the current research:

1. Tracking the _covariance_ of mental capacity attributions (Chapter III) provides a way of identifying "conceptual units." For example, if participants who endorsed Capacity X also tend to endorsed Capacities Y and Z, this provides some evidence that Capacities X, Y, and Z constitute a suite of mental capacities that are closely associated with the same underlying "conceptual unit."  
2. Tracking _asymmetries_ in mental capacity attributions (Chapter IV) provides a way of assessing the hierarchical organization of these units. For example, if many participants endorsed capacities associated with Conceptual Unit A without endorsing capacities associated with Conceptual Unit B, but very few participants did the reverse (endorsing capacities associated with Conceptual Unit B but not Conceptual Unit A), this provides some evidence that Conceptual Unit A might be considered more basic or fundamental than Conceptual Unit B, or a prerequisite for Conceptual Unit B. 
3. Tracking _which mental capacities are attributed to which target characters_ (Chapter V) provides a way of observing the application or deployment of these conceptual representations in reasoning about specific entities in the real world. For example, if participants who assessed the mental capacities of Characters 1, 2, and 3 shared one general pattern of mental capacity attributions, and participants who assessed the mental capacities of Characters 4, 5, and 6 shared another pattern, this provides some evidence that conceptual representations of mental life might play a role in structuring representations of (and interactions with) different classes of beings in the world. 

Each of these three lines of analysis requires variability across participants in which capacities (or which suites of capacities) they do or do not endorse, to what degree. (For more details on my operationalization of these general intuitions about how to analyze aspects of conceptual representation, see Chapters III-V.) This dissertation features two variants of this general approach, i.e., two different strategies for eliciting conceptual representations of mental life through variability in their mental capacity attributions: (1) asking participants to assess the mental capacities of a select number of "edge cases" in social reasoning; and (2) asking participants to assess the mental capacities of a diverse range of target characters. 

In the "edge case" variant of this experimental approach (employed in Studies 1a-1c, Study 2, and Study 4), this variability was introduced by asking participants to reason about entities that might be considered borderline cases in social reasoning: beetles and robots. This approach hinges on the fact that, at least at this point in history, the "mental lives" of beetles and robots are unknown to most ordinary people, ambiguous even during direct observation of these entities, and generally considered "up for debate," such that individual people are likely to differ in their sense of what capacities and experiences these entities might have. Thus, in the "edge case" variant of the experimental approach, the variability required for the analyses of conceptual structure just described emerges from a combination of (a) individual differences in participants' opinions or beliefs about a given target character and (b) differences between the two target characters themselves. Because beetles are animals and robots are artifacts, this particular pair also provides insight into the role of biological life in attributions of mental life—an issue of particular interest from a developmental perspective, given the long history of work on the development of the animate-inanimate distinction and its relation to folk psychology (XX CITE GELMAN & OPFER, XX CITE GELMAN & SPELKE). 

In the "diverse characters" variant of this approach (employed in Study 1d and Study 3), a wider range of target characters were included in the design of the study, including humans (e.g., adults, children), non-human animals (e.g., mammals, birds, insects), technologies (e.g., robots, computers), and inert objects (e.g., toys, tools). In these studies, different subsets of participants were asked to reason about beings with dramatically different mental capacity profiles. Thus, in the "diverse characters" variant of the experimental approach, the required variability emerged primarily from differences among the wide variety of target characters (and, to a lesser degree, individual differences in participants' opinions or beliefs about a given target character). The inclusion of many diverse target characters offers a somewhat more representative picture of the wide variety of cases in which people might reason about mental life in the real world.

Interestingly, these two strategies for eliciting variability in mental capacity attributions have turned out to yield very similar pictures of the "conceptual units" included in adults' and children's representations of mental life (Chapter III). Meanwhile, these two approaches highlight somewhat different aspects of the organization of these conceptual units (Chapter IV) and the deployment of these representations in reasoning about animate beings vs. inanimate objects (Chapter V). I return to these points in the final chapter of this dissertation (Chapter VI). [XX CHECK THAT THIS IS TRUE].

In the following sections I include specifics about the experimental design, participants, materials, and procedure for each of these studies.


# Methods

In all of the studies included in this dissertation, each participant was asked to assess 1-2 target characters (e.g., a beetle, a robot, a goat, etc.) on a wide range of sensory, perceptual, emotional, social, cognitive, and other mental capacities, ranging in number from 18-40 across studies and presented in either a random or a pseudo-random (counterbalanced) order. Participants were presented with a vivid, full-color photograph of their assigned target in a naturalistic context (e.g., a beetle on a leaf; a robot in an office; a goat in a grassy field), which they had access to throughout the study (see Figures 2.1 and 2.2). On each trial, participants were asked to assess whether the target entity was capable of a particular mental capacity. 

Below I present details about the particular target characters and mental capacities included in each study, as well as the materials and physical setup.

## Study 1: An adult endpoint

_Note: The full deatiled methods for Study 1 have been published in XX CITE Weisman et al. (2017). For the sake of comparison with Studies 2-4, I provide an abridged version here._

Study 1 was designed to investigate conceptual representations of mental life among US adults; as such, it provides an adult "endpoint" for the developmental processes under exploration in Studies 2-4.

Adults participated online via Amazon Mechanical Turk (MTurk). Participants were shown a vivid, full-color image and a label for their assigned target character(s) (e.g., "a robot"; "a beetle"), and were asked to rate the character(s) on 40 different mental capacities, presented in a random order. For each mental capacity, the participant was required to answer the question, "On a scale of 0 (Not at all capable) to 6 (Highly capable), how capable is a [target] of [capacity]?" Participants responded using this 7-point Likert-type scale. Note that in Weisman et al. (2017), this scale was recoded to run from -3 to +3 before analyses; in this dissertation, I maintain the 0 to +6 coding for comparability to Studies 2-4.

The list of 40 mental capacities employed in these studies included close variants of the 18 mental capacities featured in Gray et al.'s (XX CITE GRAY et al. 2007) study of "mind perception," as well as an additional 22 capacities generated from an a priori conceptual analysis of possible ontological categories of mental life (e.g., affective experiences, perceptual abilities, physiological sensations), with the constraint that each category should include at least five items of varying valence, complexity, and phrasing; see Table 2.1.

The set of target characters employed in these studies is presented in Figure 2.1.

Studies 1a-1c employed the "edge case" strategy for eliciting mental capacity attributions, which involved asking participants to assess the mental capacities of beetles and robots. In Studies 1a and 1b, participants (Study 1a: _n_=`r nrow(d1a_ad_wide)` US adults; Study 1b: _n_=`r nrow(d1b_ad_wide)` US adults) were randomly assigned to assess one of these two target characters on all 40 mental capacities. In Study 1c, _n_=`r nrow(d1c_ad_wide)/2` US adults were asked to assess both target characters, presented side-by-side with left-right order determined randomly, on all 40 mental capacities.

Study 1d employed the "diverse characters" strategy for eliciting mental capacity attributions, which in this case involved asking participants to assess the mental capacities of 21 target characters, spanning a wide range of potential mental capacity profiles. The list of characters included an adult, a child, an infant, a person in a persistent vegetative state, a fetus, a chimpanzee, an elephant, a dolphin, a bear, a dog, a goat, a mouse, a frog, a blue jay, a fish, a beetle, a microbe, a robot, a computer, a car, or a stapler. In Study 1d, _n_=`r nrow(d1d_ad_wide)` US adults were randomly assigned to assess one of these 21 target characters on all 40 mental capacities. 

![Figure 2.1: Target characters used in Studies 1a-1d, presented with the verbal label used to describe each character. Human characters are presented in the first row, non-human mammals in the second row, non-mammal living things in the third row, and inert objects in the fourth row. Studies 1a-1c employed the "edge case" variant of the general approach, in which participants assessed the mental capacities of beetles and robots; these characters are indicated with a black border. Study 1d employed the "diverse characters" variant of the general approach, in which participants assessed the wide variety of target characters presented here. Note that the picture used to illustrate the robot character varied between Studies 1a-1c vs. Study 1d.](design/target characters/target characters.001.jpeg)

### Data processing

All analyses were conducted on raw data, in which participants' responses were recorded as integers between 0-6. All participants were required to answer all trials, and response times were not recorded, so there were no trials with missing data.


```{r}
table2.1 <- read_csv("./design/mental_cap_list.csv") %>%
  arrange(cat_order_WDM2017, list_order_WDM2017) %>%
  select(starts_with("study"), definition_S23, definition_S4) %>%
  rename(`Definition (Studies 2-3)` = definition_S23,
         `Definition (Study 4)` = definition_S4) %>%
  mutate_all(funs(replace_na(., "-"))) %>%
  kable(format = "html", #align = c("l", rep("r", 3)),
        caption = "Table 2.1: Mental capacity items used in Studies 1-4. Capacities are grouped according to the a priori categories that guided the initial exploration of representations of mental life in Study 1 (as published in Weisman et al., 2017). In Studies 2-4, each item was associated with a preset definition (leftmost column). For items marked with an asterisk, this definition was provided to all participants; otherwise, it was provided to children (but not adults) only if they indicated that they did not understand the question. For a subset of participants in Study 3, two additional questions were asked at the very end of the study (listed under 'Additional questions (Study 3).' Study 4 included four additional items that did not align with items used in Studies 1-3 (listed under 'New items (Study 4)').") %>%
  kable_styling() %>%
  group_rows("Affective experiences (per Weisman et al., 2017)", 1, 6) %>%
  group_rows("Perceptual abilities (per Weisman et al., 2017)", 7, 11) %>%
  group_rows("Physiological sensations (per Weisman et al., 2017)", 12, 16) %>%
  group_rows("Cognitive abilities (per Weisman et al., 2017)", 17, 21) %>%
  group_rows("Agentic capacities (per Weisman et al., 2017)", 22, 26) %>%
  group_rows("Social abilities (per Weisman et al., 2017)", 27, 33) %>%
  group_rows("Other/miscellaneous (per Weisman et al., 2017)", 34, 40) %>%
  group_rows("Additional questions (Study 3)", 41, 42) %>%
  group_rows("New items (Study 4)", 43, 46)
```

```{r table2.1, include = T}
table2.1
```


## Study 2: Conceptual change between middle childhood (7-9y) and adulthood

The goal of Study 2 was to develop an experimental paradigm similar to that employed in Study 1 that could be used to explore the development of conceptual representations of mental life among children, and to conduct an initial exploration of these conceptual representations in middle childhood. Study 2 employed the "edge case" strategy used in Studies 1a-1c, with participants asked to reason about the mental lives of either a beetle or a robot. 

Pilot testing suggested that children as young as 7 years of age found the paradigm easy and enjoyable, and work on the development of lay biology and psychology has suggested that these concepts may continue to develop well into middle childhood (e.g., XX CITE Carey, 1985; Hatano & Inagaki, 1997; Piaget, 1929; cf. Gelman & Opfer, 2002). Thus, I targeted 7- to 9-year-old children for the first child sample. I also recruited a group of adults to validate this child-friendly paradigm, i.e., to evaluate whether it replicated the results of Study 1 (XX CITE Weisman et al., 2017).

Recall that, in Study 1, adult participants evaluated target characters on 40 mental capacities using a seven-point Likert-type scale. Pilot testing suggested two necessary modifications for children: rewording some of the mental capacity items, and using a simpler response scale featuring only three (rather than seven) response options: _no_, _kinda_, or _yes_. This truncated scale allowed children to move fast enough through the study to answer all 40 mental capacity questions—the top priority in the design of these studies (as discussed in the opening section of this chapter).

### Participants

In total, `r nrow(d2_ad_wide) + nrow(d2_79_wide)` people participated in this study.

```{r}
# demographics
d2_ad_gender <- demo_fun(d2_ad, "gender", 2)
d2_ad_ethnicity <- demo_fun(d2_ad, "ethnicity_cat", 2)
d2_ad_english <- demo_fun(d2_ad, "englishNative", 2)
```

Adults (_n_=`r nrow(d2_ad_wide)`) participated via MTurk in July 2016. Adult participants had gained approval for at least 95% of their previous work on MTurk; had MTurk accounts based in the US; and indicated that they were at least 18 years of age. Adults were paid \$0.30 for approximately 2-3 minutes of their time (median duration: `r summary(d2_ad$duration)["Median"] %>% round(2)` min). 

According to self report, the adult sample ranged in age from `r summary(d2_ad$age)["Min."]`-`r summary(d2_ad$age)["Max."]` years (median: `r summary(d2_ad$age)["Median"]`y) and was roughly split between women (`r d2_ad_gender$prop[d2_ad_gender$gender=="female"] * 100`%) and men (`r d2_ad_gender$prop[d2_ad_gender$gender=="male"] * 100`%; `r d2_ad_gender$prop[d2_ad_gender$gender=="other_prefNo"] * 100`% of participants identified as some other gender or opted not to disclose). Adults predominantly identified as White (`r d2_ad_ethnicity$prop[d2_ad_ethnicity$ethnicity_cat=="white"] * 100`%; `r d2_ad_ethnicity$prop[d2_ad_ethnicity$ethnicity_cat=="multi"] * 100`% identified as more than one race/ethnicity, and $\leq$ `r data.frame(d2_ad_ethnicity %>% filter(!ethnicity_cat %in% c("white", "multi")))$prop %>% max() * 100`% as any other race/ethnicity). The vast majority of adults reported English being their only native language (`r d2_ad_english$prop[d2_ad_english$englishNative == "yes_only"] * 100`%; an additional `r d2_ad_english$prop[d2_ad_english$englishNative == "yes_multiple"] * 100`% indicated that English was one of multiple native languages for them.)

```{r}
# demographics
d2_79_gender <- demo_fun(d2_79, "gender", 2)
d2_79_ethnicity <- demo_fun(d2_79, "ethnicity", 2)
d2_79_bilingual <- demo_fun(d2_79, "bilingual", 2)
```

Children (_n_=`r nrow(d2_79_wide)`) participated at one of several San Francisco Bay Area museums or at their younger sibling's preschool between July-December 2016. The study took most children under `r quantile(d2_79$duration, .75, na.rm = T) %>% as.numeric() %>% ceiling()` minutes to complete (median duration: `r summary(d2_79$duration)["Median"] %>% round(2)` min). An additional 12 children participated but were excluded for being outside the target age range (_n_=7), being of unknown age (_n_=4), or being shown a target character other than a beetle or a robot (_n_=1). Children received a small thank-you gift (e.g., a sticker) for their participation. 

Children ranged in age from `r summary(d2_79$age)["Min."] %>% round(2)`-`r summary(d2_79$age)["Max."] %>% round(2)` years (median: `r summary(d2_79$age)["Median"] %>% round(2)`y). According to parental report, the child sample included slightly more girls (`r d2_79_gender$prop[d2_79_gender$gender=="f"] * 100`%) than boys (`r d2_79_gender$prop[d2_79_gender$gender=="m"] * 100`%; `r d2_79_gender$prop[d2_79_gender$gender=="MISSING"] * 100`% of children's gender was non-binary or unknown). Parents predominantly identified their children as White (`r d2_79_ethnicity$prop[d2_79_ethnicity$ethnicity=="white"] * 100`%), multiracial (`r d2_79_ethnicity$prop[d2_79_ethnicity$ethnicity=="multi"] * 100`%), East Asian (`r d2_79_ethnicity$prop[d2_79_ethnicity$ethnicity=="east asian"] * 100`%), or South Asian (`r d2_79_ethnicity$prop[d2_79_ethnicity$ethnicity=="south or southeast asian"] * 100`%; $\leq$ `r data.frame(d2_79_ethnicity %>% filter(!ethnicity %in% c("white", "multi", "east asian", "south or southeast asian", "MISSING")))$prop %>% max() * 100`% of children were identified as any other race/ethnicity, and `r d2_79_ethnicity$prop[d2_79_ethnicity$ethnicity=="MISSING"] * 100`% of children's race/ethnicity was unknown). Roughly half of parents (`r d2_79_bilingual$prop[d2_79_bilingual$bilingual=="yes"] * 100`%) reported that their child was bilingual (though, anecdotally, parents' interpretations of "bilingual" ranged from taking classes at school to speaking a language at home).

### Materials and procedure

Study 2 employed the "edge case" variant of the general approach: Participants were randomly assigned to assess the mental capacities of either a beetle (_n_=`r d2_ad %>% filter(character == "beetle") %>% distinct(subid) %>% nrow()` adults, _n_=`r d2_79 %>% filter(character == "beetle") %>% distinct(subid) %>% nrow()` children) or a robot (_n_=`r d2_ad %>% filter(character == "robot") %>% distinct(subid) %>% nrow()` adults, _n_=`r d2_79 %>% filter(character == "robot") %>% distinct(subid) %>% nrow()` children). The images used to depict these target characters are presented in Figure 2.2.

![Figure 2.2: Target characters used in Studies 2-3, presented with the verbal label used to describe each character. Animal characters are presented in the first row, and inert objects in the second row. Studies 2 and 4 employed the "edge case" variant of the general approach, in which participants assessed the mental capacities of beetles and robots; these characters are indicated with a black border. Study 2 employed the "diverse characters" variant of the general approach, in which participants assessed the wider range of target characters presented here.](design/target characters/target characters.002.jpeg)

Instructions to participants focused on the idea that the research team wanted to know what participants thought "[beetles/robots] can do and can not do." Participants rated the target character on 40 mental capacities, presented in a random order for each participant. On each trial, participants responded _no_, _kinda_, or _yes_ to the question "Do you think a [beetle/robot] can...?" The three response options were visible throughout the experiment.

The 40 mental capacities were designed to be as close as possible to those in Study 1, while being comprehensible to children in early elementary school. As in Study 1, each a priori category included at least five items of varying valence, complexity, and phrasing; see Table 2.1.

Each item was associated with a pre-set definition or explanation, to allow the data collection team to be consistent in our responses to participants (particularly children) if they asked for clarification; see Table 2.1. Children were encouraged at the beginning of the study to ask questions if they did not know what a word meant, in which case they given these definitions; adults were told that they could access these definitions by hovering over the text on the computer screen. Pilot testing suggested that seven items required clarification for most children, so these items were always accompanied by their definitions from the beginning of the trial (for both adults and children), as follows: _have a personality, like when someone is shy and somebody else is silly_; _have beliefs, like when you think something is true_; _feel pleasure, like when something feels really good_; _have desires, like when you really want something_; _have self- control, like when you stop yourself from doing something you shouldn't do_; _have goals, like when you're trying hard to do something or make something happen_; and _feel sick, like when you feel like you might throw up_. 

Adults completed the study by clicking through a website at their own pace, with one trial presented on each page and no ability to go backwards. Children completed the study on an experimenter's laptop computer. The experimenter read the instructions and the first several trials out loud, requesting verbal responses from the child and selecting his or her response for her; after several trials, the experimenter gave the child the option to continue independently (reading the questions and selecting their answers themselves) if they desired. Roughly half of participants completed the remainder of the task independently.

### Data processing

Trials with response times that were faster than a preset criterion of 250ms were dropped, and participants were retained regardless of skipped trials. Overall, only `r missing_print_fun(d2_ad_wide)` of adults' trials (_n_=`r sum(is.na(d2_ad_wide))`) and `r missing_print_fun(d2_79_wide)` of children's trials (_n_=`r sum(is.na(d2_79_wide))`) were missing data; in these cases, I imputed missing values using the median by target character, capacity, and age group.


## Study 3: Conceptual change over early and middle childhood (4-9y)

Study 3 was designed with two goals in mind.  

First, it aimed to extend the findings with 7- to 9-year-old children in Study 2 by expanding the list of the target characters to include not only the two "edge cases" from Study 2 (a beetle and a robot), but a also a wider range of animate beings (a bird, a goat, and an elephant) and inanimate objects (a computer, a teddy bear, and a doll)—i.e., by moving from the "edge case" strategy to the "diverse characters" strategy for eliciting mental capacity attributions. 

Second, Study 3 assessed the earlier development of conceptual structure in a group of younger children: 4- to 6-year-old children. The time from 4-6 years has been identified as a period of especially dramatic development in several relevant domains, including lay psychology and theory of mind, lay biology and the animate-inanimate distinction, moral reasoning, and so on (for reviews, see XX CITE Flavell, 1999; Wellman, 2015; S. Gelman & Opfer, 2002).

### Participants

A total of `r nrow(d3_ad_wide) + nrow(d3_79_wide) + nrow(d3_46_wide)` people participated in this study, including a group of adults, a group of "older" children (7-9y), and a group of "younger" children (4-6y).

```{r}
# demographics
d3_ad_gender <- demo_fun(d3_ad, "gender", 2)
d3_ad_ethnicity <- demo_fun(d3_ad, "ethnicity_cat", 2)
```

Adults (_n_=`r nrow(d3_ad_wide)`) participated via MTurk in September 2018. Adult participants had gained approval for at least 95% of their previous work on MTurk; had MTurk accounts based in the US; and indicated that they were at least 18 years old. Adults were paid \$0.45 for approximately 2-4 minutes of their time (median duration: `r summary(d3_ad$duration)["Median"] %>% round(2)` min). An additional 22 adults participated but were excluded for failing to respond sensibly to an open-ended question about what they had been asked to do in the study (e.g., copying and pasting text from the question, writing "good study," or describing a different study, e.g., "I wrote an essay about nature"; _n_=11) or for failing to pass one or more attention checks (e.g., "Please select no"; _n_=11). According to self report, the final adult sample ranged in age from `r summary(d3_ad$age)["Min."]`-`r summary(d3_ad$age)["Max."]` years (median: `r summary(d3_ad$age)["Median"]`y) and included slightly more men (`r round(d3_ad_gender$prop[d3_ad_gender$gender=="m"], 2) * 100`%) than women (`r round(d3_ad_gender$prop[d3_ad_gender$gender=="f"], 2) * 100`%). Adults predominantly identified as White (`r d3_ad_ethnicity$prop[d3_ad_ethnicity$ethnicity_cat=="white"] * 100`%; `r d3_ad_ethnicity$prop[d3_ad_ethnicity$ethnicity_cat=="multi"] * 100`% identified as more than one race/ethnicity, and $\leq$ `r data.frame(d3_ad_ethnicity %>% filter(!ethnicity_cat %in% c("white", "multi")))$prop %>% max() * 100`% as any other race/ethnicity).

```{r}
# demographics
d3_79_gender <- demo_fun(d3_79, "gender", 2)
d3_79_ethnicity <- demo_fun(d3_79, "ethnicity", 2)
d3_46_gender <- demo_fun(d3_46, "gender", 2)
d3_46_ethnicity <- demo_fun(d3_46, "ethnicity", 2)
```

Two groups of children were recruited for this study: "older" children (7-9y) and "younger" children (4-6y). The planned sample size was 120 per age group, but the research team also retained a handful of extra participants who completed the study on the final day of data collection for each group.

The group that I refer to as "older children" (_n_=`r nrow(d3_79_wide)`) ranged in age from `r summary(d3_79$age)["Min."] %>% round(2) %>% format(nsmall = 2)`-`r summary(d3_79$age)["Max."] %>% round(2) %>% format(nsmall = 2)` years (median: `r summary(d3_79$age)["Median"] %>% round(2) %>% format(nsmall = 2)`y), and participated at one of several San Francisco Bay Area museums or at their younger sibling's preschool between July-December 2016. The study took most older children under `r quantile(d3_79$duration, .75, na.rm = T) %>% as.numeric() %>% ceiling()` minutes to complete (median duration: `r summary(d3_79$duration)["Median"] %>% round(2) %>% format(nsmall = 2)` min). According to parental report, the sample of older children included slightly more boys (`r d3_79_gender$prop[d3_79_gender$gender=="m"] * 100`%) than girls (`r d3_79_gender$prop[d3_79_gender$gender=="f"] * 100`%); `r d3_79_gender$prop[d3_79_gender$gender=="MISSING"] * 100`% of children's gender was non-binary or unknown). Parents predominantly identified their children as White (`r d3_79_ethnicity$prop[d3_79_ethnicity$ethnicity=="white"] * 100`%), South Asian (`r d3_79_ethnicity$prop[d3_79_ethnicity$ethnicity=="south or southeast asian"] * 100`%), multiracial (`r d3_79_ethnicity$prop[d3_79_ethnicity$ethnicity=="multi"] * 100`%), or East Asian (`r d3_79_ethnicity$prop[d3_79_ethnicity$ethnicity=="east asian"] * 100`%); $\leq$ `r data.frame(d3_79_ethnicity %>% filter(!ethnicity %in% c("white", "multi", "east asian", "south or southeast asian", "MISSING")))$prop %>% max() * 100`% of children were identified as any other race/ethnicity, and `r d3_79_ethnicity$prop[d3_79_ethnicity$ethnicity=="MISSING"] * 100`% of children's parents declined to provide information on their race/ethnicity. 

"Younger children" (_n_=`r nrow(d3_46_wide)`) ranged in age from `r summary(d3_46$age)["Min."] %>% round(2) %>% format(nsmall = 2)`-`r summary(d3_46$age)["Max."] %>% round(2) %>% format(nsmall = 2)` years (median: `r summary(d3_46$age)["Median"] %>% round(2) %>% format(nsmall = 2)`y), and participated either at a university-affiliated preschool or at a Bay Area museum between January-June 2017. The study took most younger children under `r quantile(d3_46$duration, .75, na.rm = T) %>% as.numeric() %>% ceiling()` minutes to complete (median duration: `r summary(d3_46$duration)["Median"] %>% round(2) %>% format(nsmall = 2)` min). According to parental report and school records, the sample of younger children included roughly the same number of girls (`r d3_46_gender$prop[d3_46_gender$gender=="m"] * 100`%) and boys (`r d3_46_gender$prop[d3_46_gender$gender=="f"] * 100`%). Children were predominantly identified as multiracial (`r d3_46_ethnicity$prop[d3_46_ethnicity$ethnicity=="multi"] * 100`%) or White (`r d3_46_ethnicity$prop[d3_46_ethnicity$ethnicity=="white"] * 100`%; $\leq$ `r data.frame(d3_46_ethnicity %>% filter(!ethnicity %in% c("white", "multi", "MISSING")))$prop %>% max() * 100`% of children were identified as any other race/ethnicity, and `r d3_46_ethnicity$prop[d3_46_ethnicity$ethnicity=="MISSING"] * 100`% of children's parents declined to provide information on their race/ethnicity).

An additional 7 children participated but were excluded for being outside the target age ranges. At museums (but not at the preschool), children received a small thank-you gift (e.g., a sticker) for their participation. 

### Materials and procedure

Pilot testing suggested that working with younger children would require making a briefer experimental paradigm with fewer than the 40 questions included in Study 2; limiting the list to 20 questions seemed to allow children as young as 4 years of age to complete the study easily and without getting bored or frustrated, while still including enough items to facilitate the exploratory "dimensionality reduction" approach to uncovering conceptual structure (Chapter III).

```{r}
d3_ad_char <- demo_fun(d3_ad, "character")
d3_79_char <- demo_fun(d3_79, "character")
d3_46_char <- demo_fun(d3_46, "character")
d3_all_char <- d3_ad_char %>% mutate(age_group = "adults") %>%
  full_join(d3_79_char %>% mutate(age_group = "children79")) %>%
  full_join(d3_46_char %>% mutate(age_group = "children46"))
```

Study 3 employed the "diverse characters" variant of the general approach. Participants were assigned to evaluate one of the following target characters: an elephant, a goat, a mouse, a bird, a beetle, a teddy bear, a doll, a robot, or a computer (_n_ per character: `r min(d3_ad_char$n)`-`r max(d3_ad_char$n)` adults, `r min(d3_79_char$n)`-`r max(d3_79_char$n)` older children, and `r min(d3_46_char$n)`-`r max(d3_46_char$n)` younger children; see Table 2.2 for exact counts). The images used to depict these target characters are presented in Figure 2.2.

```{r}
table2.2 <- d3_all_char %>%
  select(-prop) %>%
  full_join(d3_all_char %>% 
              group_by(age_group) %>% 
              summarise(n = sum(n)) %>% 
              mutate(character = "TOTAL N")) %>%
  spread(age_group, n) %>%
  mutate(character = factor(gsub("_", " ", character),
                            levels = c("elephant", "goat", "mouse", 
                                       "bird", "beetle", "robot", 
                                       "computer", "teddy bear", 
                                       "doll", "TOTAL N"))) %>%
  arrange(character) %>%
  select(character, adults, children79, children46) %>%
  rename(`older children (7-9y)` = children79,
         `younger children (4-6y)` = children46) %>%
  kable(format = "html", 
        caption = "Table 2.2: Sample sizes by target character and age group for Study 2.") %>%
  kable_styling() %>%
  row_spec(10, bold = T)
```

```{r table2.2, include = T}
table2.2
```

Participants were assigned to target characters randomly, with two exceptions: (1) The doll and teddy bear conditions were run last for older children (but included in the initial randomization scheme for adults and younger children); and (2) Toward the end of data collection with children, children were assigned to conditions that had the fewest participants. (This was not possible with adults, which is why the number of adults per condition was more variable than the number of children per condition.) As in Study 1, a vivid, high-resolution photo of the target character in a naturalistic context was visible for the duration of the study. 

Instructions and procedure were identical to Study 2, with two exceptions: (1) Participants rated the target character on 20 (rather than 40) mental capacities; and (2) For younger children, the experimenter read all questions out loud and children responded verbally. 

The 20 mental capacities were a subset of the 40 items used in Study 2, chosen to cover a similar range of capacities as included in Studies 1-2 (see Table 2.1). These items were also selected to include some of the strongest-loading items for each of the factors uncovered among adults in Study 2 (see Chapter III for further discussion). As in Study 2, each mental capacity was associated with a short, preset definition. With the exception of the item _feel sick_, which was always presented along with its definition (_like when you feel like you might throw up_) for both adults and children, these definitions were only given to children if they indicated that they did not know what a word meant; both older and younger children were encouraged at the beginning of the study to ask clarification questions. In Study 3 adult participants did not have access to these definitions.

After completing the 20 questions about mental capacities, a subset of participants also answered two additional questions: "Is a [target] made out of metal?" and "Can a [target] be turned on and off?" These questions were always asked last, were not intended to be included in any of the primary analyses, and will not be analyzed here. [XX COULD INCLUDE IN SOME APPENDIX?]

### Data processing

As in Study 2, I planned to drop trials with response times that were faster than a preset criterion of 250ms, but there were none among children, and I failed to record response times among adults. As in Study 2, participants were retained regardless of skipped trials. Overall, `r missing_print_fun(d3_ad_wide)` of adults' trials, `r missing_print_fun(d3_79_wide)` of older children's trials, and only `r missing_print_fun(d3_46_wide)` of younger children's trials (_n_=`r sum(is.na(d3_46_wide))`) were missing data. In these cases, I imputed missing values using the median by target character, capacity, and age group.

## Study 4: A focus on early childhood (4-5y)

The primary goal of Study 4 was to provide a conceptual replication and extension of Study 3, with a special focus on the youngest children included in the previous studies (4-year-old children). In light of concerns about vocabulary, attention, and use of the response scale among preschool-age children in Study 3, I designed an even more child-friendly version specifically tailored to appropriate for young preschoolers, by streamlining the experimental protocol, providing more scaffolding for the response scale, and including only vocabulary items that were pre-tested to be familiar to young preschool children. 

To extend the results of Study 3, and for the sake of completeness of the comparison between children in early childhood, middle childhood, and adulthood, in Study 4 I returned to the "edge case" strategy for eliciting mental capacity attributions, limiting the target characters to a beetle and a robot (as in Studies 1a-1c and Study 2).

### Participants

`r d4_ad %>% distinct(subid) %>% count() %>% as.numeric() + d4_46 %>% distinct(subid) %>% count() %>% as.numeric()` people participated in this study, including a group of adults and a group of 4- to 5-year-old children.

```{r}
# demographics
d4_ad_gender <- demo_fun(d4_ad, "gender", 2)
d4_ad_ethnicity <- demo_fun(d4_ad, "ethnicity_cat", 2)
```

Adults (_n_=`r d4_ad %>% distinct(subid) %>% count() %>% as.numeric()`) participated via MTurk in September 2018. Adult participants had gained approval for at least 95% of their previous work on MTurk; had MTurk accounts based in the US; and indicated that they were at least 18 years old. Adults were paid \$0.45 for approximately 2-4 minutes of their time (median duration: `r summary(d4_ad$duration)["Median"] %>% round(2)` min). An additional 21 adults participated but were excluded for failing to respond sensibly to an open-ended question about what they had been asked to do in the study (see Study 3 for examples; _n_=16) or for failing to pass one or more attention checks (e.g., "Please select no"; _n_=5). According to self report, the final adult sample ranged in age from `r summary(d4_ad$age)["Min."]`-`r summary(d4_ad$age)["Max."]` years (median: `r summary(d4_ad$age)["Median"]`y) and included slightly more men (`r round(d4_ad_gender$prop[d4_ad_gender$gender=="m"], 2) * 100`%) than women (`r round(d4_ad_gender$prop[d4_ad_gender$gender=="f"], 2) * 100`%). Adults predominantly identified as White (`r d4_ad_ethnicity$prop[d4_ad_ethnicity$ethnicity_cat=="white"] * 100`%; `r d4_ad_ethnicity$prop[d4_ad_ethnicity$ethnicity_cat=="black"] * 100`% identified as Black; `r d4_ad_ethnicity$prop[d4_ad_ethnicity$ethnicity_cat=="multi"] * 100`% identified as more than one race/ethnicity, and $\leq$ `r data.frame(d4_ad_ethnicity %>% filter(!ethnicity_cat %in% c("white", "multi")))$prop %>% max() * 100`% as any other race/ethnicity).

```{r}
# demographics
d4_46_gender <- demo_fun(d4_46, "gender", 2)
d4_46_ethnicity <- demo_fun(d4_46, "ethnicity", 2)
```

**XX CHECK WHEN SAMPLE IS COMPLETE**: The planned sample size was 100 4- to 5-year-old children. Our final sample of children (_n_=`r d4_46 %>% distinct(subid) %>% count() %>% as.numeric()`) ranged in age from `r summary(d4_46$age)["Min."] %>% round(2) %>% format(nsmall = 2)`-`r summary(d4_46$age)["Max."] %>% round(2) %>% format(nsmall = 2)` years (median: `r summary(d4_46$age)["Median"] %>% round(2) %>% format(nsmall = 2)`y), and participated at a university-affiliated preschool in the Bay Area between January-XX 2018. The research team did not record study duration. According to school records, the sample of younger children included slightly more girls (`r d4_46_gender$prop[d4_46_gender$gender=="f"] * 100`%) than boys (`r d4_46_gender$prop[d4_46_gender$gender=="m"] * 100`%). Children were predominantly identified as White (`r d4_46_ethnicity$prop[d4_46_ethnicity$ethnicity=="white"] * 100`%) or multiracial (`r d4_46_ethnicity$prop[d4_46_ethnicity$ethnicity=="multi"] * 100`%; $\leq$ `r data.frame(d4_46_ethnicity %>% filter(!ethnicity %in% c("white", "multi", "MISSING")))$prop %>% max() * 100`% of children were identified as any other race/ethnicity, and `r d4_46_ethnicity$prop[d4_46_ethnicity$ethnicity=="MISSING"] * 100`% of children's parents declined to provide information on their race/ethnicity [XX RE-CHECK BING RECORDS]).

An additional XX children participated but were excluded for being outside the target age range.

### Materials and procedure 

Materials and procedure were adapted to be more appropriate for young preschoolers, with two primary goals in mind: Streamlining the experimental protocol to improve children's comprehension and attention to the task, and limiting mental capacities to words that are highly familiar to young preschool children.

In order to streamline the experimental protocol, the task was moved off of the computer (for children but not adults); the experimenter instead used printed photographs to illustrate the target characters (measuring approximately 5 x 8 inches, printed in color and laminated) and recorded children's responses by hand. At the time of testing, the experimenter and child sat side by side at a table, with the photograph placed on the table directly in front of the child for the duration of the task. 

The introduction to the task was also streamlined. The experimenter began by placing the photograph of the first target character in front of the child and asking, "Can you tell me what this is?" If a child provided an answer other than "beetle" or "robot," the experimenter said something to the effect of, "I'm going to call it a [beetle/robot]"; otherwise, the experimenter affirmed the child's correct response. The experimenter then said, "We're going to play a game about [beetles/robots]"; reminded children, "If you ever want to stop playing, you can just let me know and we'll go back to the classroom" (per this university preschool's protocol); and then launched directly into the first question (e.g., "Can beetles get sad?").

To scaffold children's use of the three-point response scale, the experimenter provided the child with a physical representation of the scale consisting of three large boxes, separated by blank space, containing the words "NO," "KINDA," and "YES" written in large font with all capital letters (to aid children with at least some reading skills in recognizing these words); color-coded according to the intensity of response (NO = very light blue, KINDA = medium blue, YES = dark blue); and ordered from left (NO) to right (YES). Each box measured approximately 2 x 4 inches; the boxes were laminated with slightly less than 1 inch of empty space between them (through which the table was visible); see Figure 2.3. In addition to providing these visual and spatial cues to the fact that there were three response options—no, yes, and something conceptually and literally "in between" these extremes—the experimenter described (and then reiterated) these response options on the first three trials ("You can say no [pointing to NO], kinda [pointing to KINDA], or yes [pointing to YES]"). The experimenter repeated these options on the first three trials for all children, and on any other trials when a child took more than a few seconds to answer or provided a response other than saying "yes," "kinda" or "sorta," "no," or clearly pointing to one of the three options on the response scale.

![Figure 2.3: Example participant in Study 4.](design/example_participant_s4.jpeg)

For each of the two target characters (beetle, robot; see Figure 2.2), children answered 18 questions about its mental capacities; see Table 2.1. These items were chosen to be as short as possible and to be highly familiar to young preschool children. They were selected from a larger pilot study in which 3- to 5-year-old children were asked to complete stories that began with each of these mental capacities as a premise (e.g., "Let's imagine a person who _loves someone_. What happens next?"; "Now let's pretend that someone _remembers something_. What happens next?") and were judged on the appropriateness of their story completion. Items were also selected to provide a conservative test of developmental differences between younger and older children in the "conceptual units" observed in Study 3; see Chapter III for discussion. As in Studies 2-3, each mental capacity was associated with a short, preset definition (see Table 2.1). Unlike Studies 2-3, none of these definitions were considered mandatory; instead, for all 18 items, definitions were provided to children only if they expressed uncertainty about what a word meant or did not respond after prompting use of the response scale. As in Study 3, in Study 4 adult participants did not have access to these definitions.

Children first assessed all 18 mental capacities for one of the two target characters (e.g., the beetle), then completed an easy jigsaw puzzle featuring clothing and accessories appropriate for a rainy day (which took about 30-60 s to complete), and finally assessed all 18 mental capacities for the other target character (e.g., the robot).

This modified procedure—particularly moving the experiment off of the computer for children—required several changes to the experimental design. Rather than randomly assigning children to assess the beetle first or the robot first, the order of target characters was counterbalanced in advance. Likewise, rather than asking about the 18 mental capacities in a random order, questions about the first target character were asked in one of 8 pre-made random orders, and questions about the second target character were asked in the reverse order. The order of the target characters (beetle-robot or robot-beetle) and the order of the mental capacity questions (sequences 1-8) were fully crossed across participants. 

Adults participated in an online version of this same task, without a break between target characters. As in Studies 1-2, adults clicked through a website at their own pace, with one trial presented on each page and no ability to go backwards. 

### Data processing

The research team did not record response times or use this as a criterion for inclusion. As in Studies 1-3, participants were retained regardless of skipped trials. Overall `r missing_print_fun(d4_ad_wide)` of adults' trials and only `r missing_print_fun(d4_46_wide)` of children's trials (_n_=`r sum(is.na(d4_46_wide))`) were missing data; in these cases, I imputed missing values using the median by target character, capacity, and age group.

```{r}
table2.3 <- read_csv("./design/example_data.csv") %>%
  arrange(capacity) %>%
  group_by(subid) %>%
  top_n(6, capacity) %>%
  ungroup() %>%
  select(subid, age_group, age, character, capacity, response) %>%
  spread(capacity, response) %>%
  full_join(data.frame(subid = "[other participants...]")) %>%
  rename(# Study = study,
         `Participant ID` = subid,
         `Target character` = character,
         `Age group` = age_group,
         `Age (y)` = age) %>%
  mutate(`[other mental capacities...]` = "...") %>%
  mutate_all(funs(replace_na(., "..."))) %>%
  kable(format = "html", #align = c("l", rep("r", 3)),
        caption = "Table 2.3: Example data from three (hypothetical) participants. TARGET CHARACTERS: In Studies 1a, 1b, 1d, 2, and 3, each participant assessed a single target character, yielding one row of data per participant (as shown here). In Studies 1c and 4, each participant assessed two target characters, which would manifest as one additional row of data per participant. MENTAL CAPACITIES: In Studies 1a-1d and 2, each participant assessed 40 mental capacities per target character; this would manifest as 40 columns of responses to the right of the 'Target character' column. In Study 3, each participant assessed 20 mental capacities per target character (20 columns of responses); and in Study 4, each participant assessed 18 mental capacities per target character (18 columns of responses).  ADDITIONAL VARIABLES: A variety of additional variables were recorded, including the identity of the experimenter; the date, time, total duration, and location of the testing session; the gender and race/ethnicity of the participant (as well as and other demographic variables, which varied across studies and age groups); and, for each trial, response time, whether or not the participant was provided with additional clarification about the mental capacity under discussion, and other aspects of the experimental display (see 'Methods'). Only age group and exact age (in years) are shown here, since these variables were considered primary variables of interest.") %>%
  kable_styling() %>%
  column_spec(4, border_right = T)
```

```{r table2.3, include = F}
table2.3
```


# Chapter conclusion

The goal of this chapter was to provide a roadmap for the remainder of the dissertation and to describe the general approach and specific methods employed in these four studies. In the following chapters I present three analyses of this collection of datasets, beginning with an attempt to identify the "conceptual units" available to participants of different ages as they assessed the mental capacities of the target characters included in these studies. 

